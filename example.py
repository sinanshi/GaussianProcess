from gp_emulator import GaussianProcess
import gpugp
from numpy import random as random
import numpy as np
import time

def rosenbrock (x):
    """Test with simulated data generated by rosenbrock function
    see https://www.sfu.ca/~ssurjano/rosen.html
    """
    d = x.size
    xi = x[0 : (d - 1)]
    xnext = x[1 : d ]
    y = sum(100 * (xnext - xi ** 2) ** 2 + (xi - 1) ** 2)
    return y


def test_rosenbrock_gp(size, d):

    # The training dataset created from rosenbrock function
    train_x = random.uniform(-5, 10, d * size).reshape(size, d)
    train_y = np.apply_along_axis(rosenbrock, 1, train_x)
    train_y = (train_y - train_y.mean())/ train_y.std() 
    
    # The random input
    input_ = random.uniform(-5, 10, d * size).reshape(size, d)
    
    # Initialise GP
    gp = GaussianProcess.GaussianProcess(train_x, train_y)
    
    # Learn hyperparameters with CPU 
    start = time.time()
    theta_min = gp.learn_hyperparameters(n_tries=2, gpu=False)
    end = time.time()
    cpu_time = end - start
    # Predict
    pred_mu_cpu, pred_var, par_dev = gp.predict(input_)
   

    # Learn hyperparameters with GPU
    start = time.time()
    theta_min = gp.learn_hyperparameters(n_tries=2, gpu=True)
    end = time.time()
    gpu_time = end - start
    # Predict
    pred_mu_gpu, pred_var, par_dev = gp.predict(input_)



    print(pred_mu_cpu - pred_mu_gpu)
    print("gpu time: " + gpu_time)
    print("cpu time: " + cpu_time)


if __name__ == "__main__":
    test_rosenbrock_gp(30, 5) # apply GP on 30x5 data.

